{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a python library for data analysis and manipulation.\n",
    "scikit-learn is a machine learning library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been cleaned by removing the subject, sender's email address... only leaving spam/ham and email content to prevent the curse of dimensionality. No pre-processing is done (like stemming or lemmatization), as it only increases the runtime and does not yield higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\".../datasets/trec07p_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pipeline object automates the workflow and streamlines the transformation and model training.\n",
    "TF-IDF vectorizer is more refined than CountVectorizer, giving better results (adjusts for the frequency of words in general).\n",
    "\n",
    "LinearSVC is used as opposed to SVC as it is much more time-efficient and yield similar accuracy.\n",
    "I used support vector machines rather than naive Bayes classifiers, since it is designed to handle high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['label']\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# Splitting the data into training (80%) and testing (20%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning using grid search technique.\n",
    "\n",
    "Explanation of each parameter:\n",
    "- \"max_df\" - sets an upper threshold for the document frequency (the proportion of documents that contain a specific term), with any term with a higher frequency being excluded from the feature set - a form of stopwords removal\n",
    "- \"ngram_range\" - (min_n, max_n) The first range means only unigrams, and the second range means extracting both unigrams and bigrams.\n",
    "- \"sublinear_tf\" - replaces term frequency with \"1 + log(TF)\" - it reduces the impact of words with very high frequency, making the representation of terms more balanced\n",
    "- \"c\" - regularisation parameter - trade-off between low training error and low testing error (relates to overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.5, 0.75, 0.85, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"n_jobs\" - the number of CPU cores to run the task in parallel; \"-1\" uses all cores\n",
    "\n",
    "\"cv\" as an integer - the number of folds in a KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Train the model\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = grid_search.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf__C': 10, 'tfidf__max_df': 0.85, 'tfidf__ngram_range': (1, 2), 'tfidf__sublinear_tf': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      4760\n",
      "           1       1.00      1.00      1.00      5974\n",
      "\n",
      "    accuracy                           1.00     10734\n",
      "   macro avg       1.00      1.00      1.00     10734\n",
      "weighted avg       1.00      1.00      1.00     10734\n",
      "\n",
      "Classification accuracy 99.599%\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and classification report\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print results\n",
    "print('Classification accuracy {:.3%}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can load the trained model in the future to predict new emails. Using joblib - handles large numpy arrays more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spam_classifier.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and the vectorizer\n",
    "import joblib\n",
    "joblib.dump(grid_search.best_estimator_, 'spam_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation scores to estimate the model's performance on unseen data. Check whether there has been overfitting.\n",
    "\n",
    "Note that accuracy is the same with or without grid search, but there is a slight increase in cross-validation score (0.9932 → 0.9949). It may be more time- and cost-efficient to train the model without grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.99417792 0.99324639 0.99697252 0.99417792 0.99394363 0.99534125\n",
      " 0.99580713 0.99487538 0.99510832 0.99487538]\n",
      "Mean cross-validation score: 0.9948525838631385\n"
     ]
    }
   ],
   "source": [
    "# Additional diagnostics: cross-validation scores\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, x_train, y_train, cv=10)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New email input has been generated by ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted spam\n"
     ]
    }
   ],
   "source": [
    "# Using custom input to test the model\n",
    "new_email = [\"\"\"Hi there,\n",
    "\n",
    "We’re excited to offer you a special opportunity! For a limited time, you can take advantage of our exclusive promotion. This offer is only available to select individuals like you.\n",
    "\n",
    "Here’s what you’ll get:\n",
    "\n",
    "Special Discount: 50% off your first purchase\n",
    "Free Gift: A complimentary item with every order\n",
    "Limited Time Only: Act fast to secure your deal\n",
    "Don’t miss out! Click the link below to claim your offer and learn more about our exciting products.\n",
    "\n",
    "Claim Your Offer Now\n",
    "\n",
    "Best regards,\n",
    "The Special Offers Team\n",
    "\n",
    "P.S. If you have any questions, feel free to reply to this email. We’re here to help!\"\"\"]\n",
    "prediction = grid_search.predict(new_email)\n",
    "print(\"predicted spam\") if prediction == [1] else print(\"predicted ham\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
